# CNN - Forward Activations & Poolling

By Leon Davis.

Este proyecto implementa una red CNN (solo forward) entrenada para reconocer d√≠gitos del 0 al 9 utilizando el dataset MNIST. Se ha desarrollado en C++ usando CMake como sistema de construcci√≥n y OpenCV para el manejo de im√°genes.

## üîß Requisitos

* CMake >= 3.10
* OpenCV >= 4.0

Aseg√∫rate de tener instalados los requisitos antes de compilar.

## Instalaci√≥n

Clona el repositorio y entra en la carpeta del proyecto:

```bash
git clone https://github.com/LeonDavisCoropuna/MLP-Multi-Layer-Perceptron.git
cd MLP-Multi-Layer-Perceptron
```

Dale permisos de ejecuci√≥n al script principal:

```bash
chmod +x run.sh
```

Ejecuta el script para compilar y correr (test o main):

```bash
./run.sh main
```


### 1. Implementaci√≥n
Este documento describe la implementaci√≥n de tres componentes fundamentales para redes neuronales convolucionales:
1. Capa convolucional (`Conv2DLayer`)
2. Capa de pooling m√°ximo (`PoolingLayer`)
3. Capa de aplanamiento (`FlattenLayer`)

### 2. Implementaci√≥n de la Convoluci√≥n 2D

#### 2.1. Estructura de la Capa Convolucional
La clase `Conv2DLayer` implementa la operaci√≥n de convoluci√≥n discreta 2D con las siguientes caracter√≠sticas:
- Soporte para m√∫ltiples canales de entrada y salida
- Inicializaci√≥n de pesos con el m√©todo He normal
- Aplicaci√≥n opcional de funciones de activaci√≥n

```cpp
Conv2DLayer(int in_channels, int out_channels, int kernel_size, 
            int in_height, int in_width, 
            ActivationFunction* act = nullptr, 
            Optimizer* opt = nullptr)
```

#### 2.2. Proceso de Convoluci√≥n (Forward Pass)
El m√©todo `forward` implementa la operaci√≥n principal:

1. **Validaci√≥n de dimensiones**:
   - Verifica que el tensor de entrada tenga las dimensiones esperadas `[batch_size, in_channels, in_height, in_width]`

2. **Operaci√≥n de convoluci√≥n**:
   - Seis bucles anidados implementan:
     - Canales de salida (co)
     - Posiciones espaciales (h, w)
     - Canales de entrada (ci)
     - Posiciones del kernel (kh, kw)

3. **C√°lculo de cada elemento de salida**:
   ```cpp
   sum += inputs.data[ci*in_height*in_width + input_h*in_width + input_w] * 
          weights.data[co*in_channels*kernel_size*kernel_size + 
                      ci*kernel_size*kernel_size + 
                      kh*kernel_size + kw];
   ```

### 4. Implementaci√≥n de Flatten

#### 4.1. Estructura de la Capa
La clase `FlattenLayer` transforma tensores multidimensionales en vectores 1D:

```cpp
Tensor forward(const Tensor &input) {
    input_shape = input.shape;
    outputs = input;
    outputs.reshape({static_cast<int>(input.size())});
    return outputs;
}
```

#### 4.2. Ejemplo
Entrada nx2√ó3√ó3 ‚Üí Salida nx18, donde n es el batch_size

## Ejemplos

### Ejemplo 1: Sin activaciones y con Max Pooling

Este ejemplo demuestra el uso b√°sico de una red convolucional sin funciones de activaci√≥n y con una capa de **MaxPooling**. Se sigue de una capa de **Flatten** para convertir la salida final en un vector plano.

#### Arquitectura usada:

1. **Conv2DLayer**:

   * Input: 1 canal, imagen 6x6
   * Filtros: 5
   * Kernel: 3x3
   * Stride: 1
   * Padding: 0
     ‚Üí Resultado: 5 mapas de 4x4

2. **MaxPooling**:

   * Tipo: MaxPooling
   * Tama√±o del kernel: 2x2
   * Stride: 2
     ‚Üí Resultado: 5 mapas de 2x2

3. **Flatten**:

   * Aplana la salida \[1, 5, 2, 2] ‚Üí \[1, 20]

---

#### Entrada:

Imagen de 6x6 con un solo canal (batch size 1):

```
[[1, 2, 3, 4, 5, 2],
 [6, 7, 8, 9, 1, 3],
 [2, 3, 4, 5, 6, 4],
 [7, 8, 9, 1, 2, 1],
 [3, 4, 5, 6, 7, 2],
 [7, 5, 6, 1, 2, 3]]
```

---

#### Salida:

```txt
Output shape: 
1, 20, 
Output flatten: 
0.793082 -5.9289 -1.12534 -0.935543 -3.49811 
-2.28402 -0.958616 -0.183638 9.78294 2.67549 
4.25849 5.16243 -9.7859 -7.22758 -7.13639 
-3.12177 -9.05591 -12.3485 -11.4881 -8.56649
```

* No se usaron funciones de activaci√≥n como ReLU, por eso algunos valores negativos permanecen.

* MaxPooling reduce el tama√±o espacial pero retiene los valores m√°s altos.

### Ejemplo 2: Con activaci√≥n ReLU y Max Pooling

Este ejemplo muestra c√≥mo usar una red convolucional con una **funci√≥n de activaci√≥n ReLU** seguida de una capa de **MaxPooling**. Finalmente, se usa una capa **Flatten** para convertir el resultado en un vector plano.

#### Arquitectura usada:

1. **Conv2DLayer**:

   * Input: 1 canal, imagen 6x6
   * Filtros: 5
   * Kernel: 3x3
   * Stride: 1
   * Padding: 0
   * Activaci√≥n: **ReLU**
     ‚Üí Resultado: 5 mapas de 4x4

2. **MaxPooling**:

   * Tipo: MaxPooling
   * Tama√±o del kernel: 2x2
   * Stride: 2
     ‚Üí Resultado: 5 mapas de 2x2

3. **Flatten**:

   * Aplana la salida \[1, 5, 2, 2] ‚Üí \[1, 20]

#### Entrada:

Imagen de 6x6 con un solo canal (batch size 1):

```
[[1, 2, 3, 4, 5, 2],
 [6, 7, 8, 9, 1, 3],
 [2, 3, 4, 5, 6, 4],
 [7, 8, 9, 1, 2, 1],
 [3, 4, 5, 6, 7, 2],
 [7, 5, 6, 1, 2, 3]]
```

#### Procesamiento:

* **ReLU** elimina los valores negativos producidos por la convoluci√≥n, manteniendo solo valores positivos.
* **MaxPooling** extrae el valor m√°ximo de cada ventana de 2x2, reduciendo el tama√±o espacial.
* **Flatten** convierte los mapas resultantes en un vector de una dimensi√≥n por muestra.

#### Salida:

```txt
Output shape: 
1, 20, 
Output flatten: 
10.6127 9.88491 12.8101 11.5919 14.9325 
8.56061 12.4502 10.3441 0 0 
0 0 21.007 19.4829 17.6718 
13.8947 18.2899 16.2002 20.1031 18.2886
```

* Los **valores en cero** indican posiciones donde la salida de la convoluci√≥n fue negativa y fue anulada por **ReLU**.


### Ejemplo 3: Sin activaciones y con Average Pooling

En este ejemplo se muestra c√≥mo aplicar una capa convolucional sin activaci√≥n, seguida de **AveragePooling**. Esto es √∫til cuando queremos suavizar la informaci√≥n extra√≠da sin eliminar valores negativos, como lo har√≠a ReLU.

#### Arquitectura usada:

1. **Conv2DLayer**:

   * Input: 1 canal, imagen 6x6
   * Filtros: 5
   * Kernel: 3x3
   * Stride: 1
   * Padding: 0
   * Activaci√≥n: **Sin activaci√≥n**
     ‚Üí Resultado: 5 mapas de 4x4

2. **Average Pooling**:

   * Tipo: AveragePooling
   * Kernel: 2x2
   * Stride: 2
     ‚Üí Resultado: 5 mapas de 2x2

3. **Flatten**:

   * Aplana la salida \[1, 5, 2, 2] ‚Üí \[1, 20]

---

#### Entrada:

Imagen de 6x6 con un solo canal (batch size 1):

```
[[1, 2, 3, 4, 5, 2],
 [6, 7, 8, 9, 1, 3],
 [2, 3, 4, 5, 6, 4],
 [7, 8, 9, 1, 2, 1],
 [3, 4, 5, 6, 7, 2],
 [7, 5, 6, 1, 2, 3]]
```

#### Procesamiento:

* **Convoluci√≥n** calcula valores directamente sin activar (puede haber valores negativos).
* **AveragePooling** toma el promedio de cada regi√≥n 2x2, resultando en una forma m√°s suavizada del mapa.
* **Flatten** convierte el resultado final en un vector unidimensional.

#### Salida:

```txt
Output shape: 
1, 20, 
Output flatten: 
-3.62878 -0.616202 -3.53962 -0.841309 12.1367 
7.34708 10.1393 7.60364 5.37771 4.61682 
5.23455 3.93105 1.34808 -2.21956 -0.275996 
-0.16257 5.34664 2.83822 4.03089 4.50018
```

### Ejemplo 4: Con activaci√≥n Sigmoid y Average Pooling

Este ejemplo implementa un pipeline donde se aplica una convoluci√≥n con funci√≥n de activaci√≥n **Sigmoid**, seguida de una capa de **Average Pooling** y finalmente un **aplanamiento (flatten)**. Este flujo es √∫til cuando se desea una salida normalizada entre 0 y 1, lo cual puede ser √∫til para tareas de clasificaci√≥n o detecci√≥n temprana de patrones suaves.

#### Arquitectura usada:

1. **Conv2DLayer**:

   * Input: 1 canal, imagen 6x6
   * Filtros: 5
   * Kernel: 3x3
   * Stride: 1
   * Padding: 0
   * Activaci√≥n: **Sigmoid**
     ‚Üí Resultado: 5 mapas de 4x4 con valores en \[0, 1]

2. **Average Pooling**:

   * Tipo: Promedio (AVG)
   * Kernel: 2x2
   * Stride: 2
     ‚Üí Resultado: 5 mapas de 2x2

3. **Flatten**:

   * Aplana la salida \[1, 5, 2, 2] ‚Üí \[1, 20]

#### Entrada:

Imagen de 6x6 con un solo canal (batch size 1):

```
[[1, 2, 3, 4, 5, 2],
 [6, 7, 8, 9, 1, 3],
 [2, 3, 4, 5, 6, 4],
 [7, 8, 9, 1, 2, 1],
 [3, 4, 5, 6, 7, 2],
 [7, 5, 6, 1, 2, 3]]
```

#### Procesamiento:

* La activaci√≥n **Sigmoid** transforma los valores de la convoluci√≥n a un rango entre 0 y 1.
* **AveragePooling** suaviza estos mapas activados, produciendo un resumen por regi√≥n.
* **Flatten** convierte el resultado en un vector para posibles capas densas.

#### Salida:

```txt
Output shape: 
1, 20, 
Output flatten: 
0.999984 0.606272 0.762367 0.989349 0.540815 
0.996577 0.963949 0.729454 0.00425285 0.000883663 
0.0011998 0.00469638 0.995544 0.94144 0.959841 
0.938997 2.23468e-05 0.00151703 9.12039e-05 0.00085884
```


* La **funci√≥n Sigmoid** produce activaciones suaves y normalizadas, pero **puede saturarse** f√°cilmente, como se ve con algunos valores muy cercanos a 0 o 1.
* En conjunto con **AveragePooling**, los valores tienden a estabilizarse a√∫n m√°s, pero **la p√©rdida de informaci√≥n** puede aumentar si los mapas son muy peque√±os.


Perfecto, Leon. Aqu√≠ tienes la documentaci√≥n para el **Ejemplo 5**, que emplea la funci√≥n de activaci√≥n **Tanh** y usa **Average Pooling**:

---

## Ejemplo 5: Con activaci√≥n Tanh y Average Pooling

Este ejemplo muestra el uso de la activaci√≥n **Tanh** en una capa convolucional, seguida por una capa de **Average Pooling** y una **capa Flatten**. La funci√≥n Tanh es √∫til cuando se requiere que las activaciones est√©n centradas en cero, lo cual puede ayudar a la convergencia durante el entrenamiento.

#### Arquitectura usada:

1. **Conv2DLayer**:

   * Input: 1 canal, imagen 6x6
   * Filtros: 5
   * Kernel: 3x3
   * Stride: 1
   * Padding: 0
   * Activaci√≥n: ‚úÖ **Tanh**
     ‚Üí Resultado: 5 mapas de activaci√≥n de 4x4 en el rango \[-1, 1]

2. **Average Pooling**:

   * Tipo: Promedio (AVG)
   * Kernel: 2x2
   * Stride: 2
     ‚Üí Resultado: 5 mapas de 2x2

3. **Flatten**:

   * Convierte la salida \[1, 5, 2, 2] ‚Üí \[1, 20]

#### Entrada:

Imagen 6x6 con un solo canal (batch size 1):

```
[[1, 2, 3, 4, 5, 2],
 [6, 7, 8, 9, 1, 3],
 [2, 3, 4, 5, 6, 4],
 [7, 8, 9, 1, 2, 1],
 [3, 4, 5, 6, 7, 2],
 [7, 5, 6, 1, 2, 3]]
```

---

#### Procesamiento:

* **Tanh** normaliza los valores de activaci√≥n a un rango entre -1 y 1, centr√°ndolos alrededor de cero.
* **Average Pooling** reduce dimensionalidad promediando los valores en cada regi√≥n.
* **Flatten** transforma la salida en un vector para su uso en capas densas o clasificaci√≥n.

---

#### Salida:

```txt
Output shape: 
1, 20, 
Output flatten: 
1 1 1 1 -0.909747 -0.998934 -0.999856 -0.999682 
-0.491054 -0.109679 -0.766465 0.00354612 -0.00429182 
-0.173439 -0.101511 -0.499644 -0.999908 -0.509348 
-0.999943 -0.432831
```

* La salida muestra c√≥mo **Tanh satura** en ¬±1 cuando las activaciones de la convoluci√≥n son muy grandes o peque√±as.
* Es √∫til cuando se quiere mantener la se√±al centrada y sim√©trica, aunque puede saturarse m√°s que ReLU o Sigmoid.

## Intento de entrenamiento

![alt text](images/training-cnn.png)
Ahora si llega a entrenar y las m√©tricas se guardan en training_log.csv

## 5. Conclusiones

1. Se implement√≥ exitosamente la convoluci√≥n 2D con soporte para:
   - M√∫ltiples filtros (canales de salida)
   - Validaci√≥n dimensional estricta
   - Inicializaci√≥n adecuada de pesos

2. El pooling m√°ximo incluye:
   - Configuraci√≥n flexible de kernel y stride
   - Mecanismo para backpropagation (√≠ndices m√°ximos)
   - Validaci√≥n de compatibilidad dimensional

3. El c√≥digo cumple con los requisitos solicitados:
   - Operaciones b√°sicas de CNN
   - Manejo adecuado de dimensiones
   - Estructura clara y documentada


## Ver c√≥digo en github:
La parte principal del c√≥digo se encuentra en la carpeta models/ (model,trainer, layers) y en utils/ (optimizadores, funciones de perdida y activaci√≥n y otros)
```bash
https://github.com/LeonDavisCoropuna/MLP-Multi-Layer-Perceptron.git
```